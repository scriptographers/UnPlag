Plagiarism detection as considered in this paper is a computational means of
detecting the above mentioned plagiarism violations. As such it includes copy
detection, which is the most straightforward case of plagiarism that duplicates
parts of documents verbatim. Copy detection is not necessarily useful strictly
for unlawful violations; a possible scenario is one where user is activelly sifting
through documents from a 
For each file, you could calculate its signature vector. For each file F[i], first compute a vector of integers that corresponds to the number of times each word occurs. You don’t need to store the actual word. Sort this vector. Call it the “signature”. The vectors probably won’t be of equal length, so you may have to pad them for what follows. For a fixed index j, normalise F[:, j], that is, subtract the mean and divide by standard deviation. 
particular domain. Here the ‘original’, or registered
documents are simply documents that have been seen already, and the user
is likely not interested in minor modifications (retransmitted or forwarded
messages, different versions or editions of the same work, documents coming
from mirror sites and so on). He aims to gather topically related documents,
without any explicit regard to plagiarism. This is a task studied in the field of
Information Retrieval (IR), and indeed in general terms plagiarism detection in
digital libraries can be seen as an instance of IR.