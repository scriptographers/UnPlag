{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from ctokenizer import CTokenizer\n",
    "from matplotlib import pyplot as plt\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = \"../datasets/cpp_repo/\"\n",
    "TRAIN_PATH_2 = \n",
    "FILE_RE   = \"*.cpp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 397/397 [03:39<00:00,  1.81it/s]\n"
     ]
    }
   ],
   "source": [
    "files = []\n",
    "problematic_files = []\n",
    "for filepath in tqdm(glob.glob(os.path.join(TRAIN_PATH, FILE_RE))):\n",
    "    t = CTokenizer(filepath)\n",
    "    tokens = t.rawTokenization()\n",
    "    # tokens_joined = \" \".join(tokens)\n",
    "    if len(tokens) > 0:\n",
    "        files.append(tokens)\n",
    "    else:\n",
    "        # Files which result in empty tokens\n",
    "        problematic_files.append(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following files have some problem: \n",
      "../datasets/cpp_repo/0011.cpp\n",
      "../datasets/cpp_repo/0042.cpp\n",
      "../datasets/cpp_repo/0047.cpp\n",
      "../datasets/cpp_repo/0050.cpp\n",
      "../datasets/cpp_repo/0113.cpp\n",
      "../datasets/cpp_repo/0125.cpp\n",
      "../datasets/cpp_repo/0128.cpp\n",
      "../datasets/cpp_repo/0136.cpp\n",
      "../datasets/cpp_repo/0156.cpp\n",
      "../datasets/cpp_repo/0165.cpp\n",
      "../datasets/cpp_repo/0186.cpp\n",
      "../datasets/cpp_repo/0237.cpp\n",
      "../datasets/cpp_repo/0292.cpp\n",
      "../datasets/cpp_repo/0297.cpp\n",
      "../datasets/cpp_repo/0305.cpp\n",
      "../datasets/cpp_repo/0318.cpp\n",
      "../datasets/cpp_repo/0326.cpp\n",
      "../datasets/cpp_repo/0343.cpp\n",
      "../datasets/cpp_repo/0372.cpp\n",
      "../datasets/cpp_repo/0376.cpp\n",
      "../datasets/cpp_repo/0382.cpp\n"
     ]
    }
   ],
   "source": [
    "# Show problematic files\n",
    "if len(problematic_files) > 0:\n",
    "    print(\"The following files have some problem: \")\n",
    "    for pf in problematic_files:\n",
    "        print(pf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_DOCS = len(files)\n",
    "\n",
    "tagged_data = [\n",
    "    TaggedDocument(words=file, tags=[i]) \n",
    "    for i, file in enumerate(files)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doc2Vec Model: documentation: https://radimrehurek.com/gensim/models/doc2vec.html\n",
    "\n",
    "## Hyper-parameters:\n",
    "embedding_dimension = 100\n",
    "lr = 0.025 # Initial learning rate\n",
    "min_count = 10 # Ignore all words having frequency less than 10\n",
    "N_EPOCHS = 100\n",
    "\n",
    "## Initialize model:\n",
    "model = Doc2Vec(\n",
    "    dm = 0, # Use distributed BoW\n",
    "    vector_size = embedding_dimension, \n",
    "    # alpha = lr, \n",
    "    min_count = min_count,\n",
    "    epochs = N_EPOCHS\n",
    ")\n",
    "\n",
    "## Build vocab:\n",
    "model.build_vocab(tagged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on our own data from scratch\n",
    "model.train(\n",
    "    tagged_data, \n",
    "    total_examples=model.corpus_count, \n",
    "    epochs=model.epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"models/d2v_cpp.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
